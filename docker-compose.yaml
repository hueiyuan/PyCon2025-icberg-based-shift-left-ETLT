version: '3.8'

services:
  postgres: ## Nessie 的 backend-database (儲存 nessie 的 metadatam, ex. branch, commit)
    image: postgres:13
    container_name: postgres
    ports:
      - "5432:5432"
    environment:
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=${POSTGRES_DB}
    volumes:
      - postgres-data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
      interval: 5s
      timeout: 5s
      retries: 5

  minio:
    image: minio/minio:latest
    container_name: minio
    ports:
      - "9000:9000" # API Port
      - "9091:9091" # Console Port
    environment:
      - MINIO_ROOT_USER=${MINIO_ROOT_USER}
      - MINIO_ROOT_PASSWORD=${MINIO_ROOT_PASSWORD}
    volumes:
      - minio-data:/data
    command: server /data --console-address ":9091"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 5s
      timeout: 2s
      retries: 5

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: kafka
    ports:
      - "9092:9092"
      - "29092:29092"
      - "9093:9093"
    environment:
      # KRaft settings
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: 'broker,controller'
      KAFKA_CONTROLLER_QUORUM_VOTERS: '1@kafka:9093'
      KAFKA_LISTENERS: 'PLAINTEXT://kafka:29092,CONTROLLER://kafka:9093,PLAINTEXT_HOST://0.0.0.0:9092'
      KAFKA_ADVERTISED_LISTENERS: 'PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092'
      KAFKA_CONTROLLER_LISTENER_NAMES: 'CONTROLLER'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: 'CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT'
      KAFKA_INTER_BROKER_LISTENER_NAME: 'PLAINTEXT'
      # Storage settings
      KAFKA_LOG_DIRS: '/var/lib/kafka/data'
      CLUSTER_ID: '${KAFKA_CLUSTER_ID}'
      # Topic settings
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
    volumes:
      - kafka-data:/var/lib/kafka/data
    user: "appuser"
    healthcheck:
      test: ["CMD", "kafka-broker-api-versions", "--bootstrap-server", "localhost:9092"]
      interval: 10s
      timeout: 5s
      retries: 5

  schema-registry:
    image: confluentinc/cp-schema-registry:7.5.0
    container_name: schema-registry
    ports:
      - "8081:8081"
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: kafka:29092
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081
    depends_on:
      kafka:
        condition: service_healthy

  nessie:
    image: projectnessie/nessie:0.75.0 # Pinning version for stability
    container_name: nessie
    ports:
      - "19120:19120"
    environment:
      - NESSIE_VERSION_STORE_TYPE=JDBC
      - QUARKUS_DATASOURCE_DB_KIND=postgresql
      - QUARKUS_DATASOURCE_JDBC_URL=jdbc:postgresql://postgres:5432/${POSTGRES_DB}
      - QUARKUS_DATASOURCE_USERNAME=${POSTGRES_USER}
      - QUARKUS_DATASOURCE_PASSWORD=${POSTGRES_PASSWORD}
    depends_on:
      postgres:
        condition: service_healthy

  trino-coordinator:
    image: trinodb/trino:435
    container_name: trino-coordinator
    ports:
      - "8080:8080"
    volumes:
      - ./trino:/etc/trino
    depends_on:
      - nessie
      - minio

  dbt:
    image: python:3.12-slim
    platform: ${PLATFORM} # Specify platform for Apple Silicon (M1/M2/M3) to fix 'cannot execute binary file' error
    container_name: dbt
    working_dir: /usr/app/dbt
    entrypoint: /bin/bash
    # 在啟動時更新套件列表、安裝 git，然後再安裝 python 套件
    # Correctly format command as a list of arguments for the entrypoint
    command: [ "-c", "apt-get update && apt-get install -y --no-install-recommends git && pip install dbt-trino && tail -f /dev/null" ]
    volumes:
      - ./dbt_project:/usr/app/dbt
      - ./dbt_profiles:/root/.dbt/
    depends_on:
      - trino-coordinator

  spark:
    image: bitnami/spark:3.5
    container_name: spark
    platform: ${PLATFORM} # For Apple Silicon. Use linux/amd64 for Intel/AMD.
    user: root # To avoid permission issues when installing packages
    environment:
      - S3_ACCESS_KEY=${MINIO_ROOT_USER}
      - S3_SECRET_KEY=${MINIO_ROOT_PASSWORD}
    volumes:
      - ./spark/apps:/apps
      - ./spark/conf/spark-defaults.conf:/opt/bitnami/spark/conf/spark-defaults.conf
    command: tail -f /dev/null # Keep the container running for exec
    depends_on:
      - nessie
      - minio
      - kafka
      - schema-registry

  dbt-docs:
    image: python:3.12-slim
    platform: ${PLATFORM} # Specify platform for Apple Silicon
    container_name: dbt-docs
    working_dir: /usr/app/dbt
    ports:
      - "8082:8082" # Port for dbt docs serve
    volumes:
      - ./dbt_project:/usr/app/dbt
      - ./dbt_profiles:/root/.dbt/
    command: >
      bash -c "
        apt-get update && 
        apt-get install -y --no-install-recommends git && 
        pip install dbt-trino &&
        dbt deps &&
        dbt docs generate &&
        dbt docs serve --port 8082 --host 0.0.0.0
      "
    depends_on:
      - trino-coordinator
    restart: unless-stopped

volumes:
  postgres-data:
  minio-data:
  kafka-data:
